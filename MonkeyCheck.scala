package org.scalacheck

import scala.util.Random

object MonkeyCheck {

  import Between._

  // Properties are what we check automatically.
  type Property[-T]  = T => Boolean

  // Generators generate arbitrary inputs to properties.
  type Generator[+T] = Parameters => Option[T]

  case class Parameters(size: Int, random: Random)

  trait G[T] extends Generator[T] {

    /*
     * Take a value that was generated by this generator return a
     * stream of "shrunken" values. The basic idea is that the values
     * in the stream are ones that could have been generated by the
     * generator but which are likely to be a more minimal test case.
     */
    def shrink(value: T): Stream[T] = Stream.empty

  }


  // To shrink test case we need to be able to check whether a
  // shrunken value could have been generated by the original
  // generator. Which can be arbitrarily hard if the generator
  // contains, say, a map. for instance:
  //
  //  generator[Int].map(_ * 2)
  //
  // only generates even ints. But a general purpose shrinker for ints
  // might try subtracting 1 from the original value, producing a
  // value that the generator would never have generated.
  //
  // One case one could catch this (and which scalacheck seems to do)
  // is generators created by adding a filter: save the filter and
  // then apply it to values produced by the shrinker. I assume this
  // is why in scalacheck there are some seemingly redundant calls to
  // suchThat on some of the generators--those calls install a filter
  // which will then be used by the shrinkers. But since you can also
  // change the range of possible generated values with a map or
  // flatMap, the shrinking mechanism is not really 100%
  // correct. Perhaps the thing to do is to specify a generator as
  // both a generation function and a shrinking function.
  //
  // So to be fully general, the shrinker and the generator need to be
  // somewhat tightly coupled. To be fully correct, the shrinker needs
  // to be a function from the set of values possibly produced by the
  // generator only to other such values. One way to arrange that is
  // to make sure that

  // Another possibly useful thing would be to instead of shrinking
  // the value, to shrink the generator to something that produces
  // values in a smaller space but that still includes the failing
  // value. For instance, if our original generator generated totally
  // arbitrary Ints and our test failed at value N, then we could
  // shrink that to a generator that only generated ints that are near
  // N or multiples of N or other subsets of Ints. This could actually
  // serve to find not only a minimal test case (which doesn't
  // actually make sense for an Int value) but to possibly find where
  // in the number line the problem lies. I.e. if all values < M are
  // okay and M < N we're more interested in M than N.
  //
  // For tuple generators, the same basic trick applies, for an
  // N-tuple, use N new generators each with one of the element
  // generators shrunk.
  //
  // But in more general cases where the space is multidimensional
  // (e.g. a generator of tuples)

  // To shrink a value produced by a mapped generator ... we're kind
  // of screwed. Only way to reliably shrink the output of such a
  // generator is to construct a compatible shrinker. Which can
  // certainly be done for the arbitrary generators since all we care
  // is that it's an instance of the right type. And we can handle the
  // case where we have a generator that we know how to shrink and we
  // add a filter.

  // Arbitrary generator: arbitrary shrinker
  // Filtered generator: arbitrary shrinker + same filter
  // Mapped generator: no good answer.
  // FlatMapped generator: if we assume it's a composed

  implicit class RichGenerator[T](g: Generator[T]) {
    def map[U](fn: T => U): Generator[U]                = { ps => g(ps).map(fn) }
    def flatMap[U](fn: T => Generator[U]): Generator[U] = { ps => g(ps).flatMap(fn(_)(ps)) }
    def filter(fn: T => Boolean): Generator[T]          = { ps => g(ps).filter(fn) }
  }


  // Public methods for getting generators.

  def arbitrary[T](ps: Parameters)(implicit g: Generator[T]): Option[T] = g.apply(ps)

  def generator[T](implicit g: Generator[T]): Generator[T] = g
  def between[T](min: T, max: T)(implicit b: Between[T]): Generator[T] = b(min, max)
  def oneOf[T](xs: Seq[T]): Generator[T] = between(0, xs.size - 1).map(xs(_))
  def oneOf[T](t: T, ts: T*): Generator[T] = oneOf[T](t +: ts)

  def betwixt[T](min: T, max: T, p: Parameters)(implicit b: Between[T]): Option[T] = b(min, max)(p)

  // Arbitrary generators are the base case generators for when all we
  // know about what we want is the type. If you want to have them
  // accessible, you'll want to import MonkeyCheck.Arbitrary._
  object Arbitrary {

    implicit lazy val byteG = new G[Byte] {
      def apply(p: Parameters) = betwixt(Byte.MinValue, Byte.MaxValue, p)
    }

    implicit lazy val arbitraryByte:    Generator[Byte]    = between(Byte.MinValue, Byte.MaxValue)
    implicit lazy val arbitraryChar:    Generator[Char]    = between(Char.MinValue, Char.MaxValue)
    implicit lazy val arbitraryShort:   Generator[Short]   = between(Short.MinValue, Short.MaxValue)
    implicit lazy val arbitraryInt:     Generator[Int]     = between(Int.MinValue, Int.MaxValue)
    implicit lazy val arbitraryLong:    Generator[Long]    = between(Long.MinValue, Long.MaxValue)
    implicit lazy val arbitraryFloat:   Generator[Float]   = between(Float.MinValue, Float.MaxValue)
    implicit lazy val arbitraryDouble:  Generator[Double]  = between(Double.MinValue, Double.MaxValue)
    implicit lazy val arbitraryBoolean: Generator[Boolean] = { ps => Some(ps.random.nextBoolean) }
    implicit lazy val arbitraryUnit:    Generator[Unit]    = { ps => Some(()) }

    implicit lazy val arbitraryAnyVal: Generator[AnyVal] = { ps =>
      oneOf(
        arbitraryByte, arbitraryChar, arbitraryShort, arbitraryInt, arbitraryLong,
        arbitraryFloat, arbitraryDouble, arbitraryBoolean, arbitraryUnit)
        .apply(ps)
        .flatMap(_.apply(ps))
    }

    // In scalacheck, the arbitrary option goes through some
    // machinations with the size. At least part of the point, I
    // think, is that we probably want to mostly return Somes whereas
    // this returns None half the time.
    implicit def arbitraryOption[T:Generator]: Generator[Option[T]] = { ps =>
      if (ps.random.nextBoolean) None else Some(generator[T].apply(ps)) }

    implicit def arbitraryEither[T:Generator, U:Generator]: Generator[Either[T, U]] = { ps =>
      if (ps.random.nextBoolean) {
        arbitrary[T](ps).map(Left(_))
      } else {
        arbitrary[U](ps).map(Right(_))
      }
    }

    ////////////////////////////////////////////////////////////////////////
    // Tuples

    implicit def arbitraryTuple1[T:Generator] =
      for { t <- generator[T] } yield Tuple1(t)

    implicit def arbitraryTuple2[T1:Generator, T2:Generator] =
      for {
        t1 <- generator[T1]
        t2 <- generator[T2]
      } yield (t1, t2)

    implicit def arbitraryTuple3[T1:Generator, T2:Generator, T3:Generator] =
      for {
        t1 <- generator[T1]
        t2 <- generator[T2]
        t3 <- generator[T3]
      } yield (t1, t2, t3)

    // In some sense the previous generator knows how it generated the
    // three parts of the tuple. To make a stream of shrunk tuples
    // from a particular tuple it needs to make one stream for each
    // element with values that contain a shrunk version of that
    // element and the other two as in the original tuple being
    // shrunk. Is this generally applicable? I.e. can the output of a
    // generator that has been created by flatMapping always be



    // TODO: tuples up to 22

    // TODO: Buildable containers, both seqs and maps.


    // Not clear how useful these arbitrary functions really are since
    // each generated function returns the same value regardless of
    // input. Perhaps of more use would be something that given a set
    // of properties of a function, can generate a function that
    // satisfies those properties. Thus if you have some code you
    // actually need to test that takes a function as an argument

    implicit def arbitraryFunction1[T1,R:Generator]: Generator[T1 => R] = { ps =>
      for { r <- arbitrary[R](ps) } yield (t1: T1) => r
    }

    implicit def arbitraryFunction2[T1,T2,R:Generator]: Generator[(T1, T2) => R] = { ps =>
      for { r <- arbitrary[R](ps) } yield (t1: T1, t2: T2) => r
    }

  }
  object Between {
    // Used internally to make generators for ordered things like numbers.
    type Between[T] = (T, T) => Generator[T]

    private def chooseLong(low: Long, high: Long, random: => Long): Option[Long] = {
      if (low <= high) Some(low + math.abs(random % ((high - low) + 1))) else None
    }

    private def chooseDouble(low: Double, high: Double, random: => Double): Option[Double] = {
      if (low <= high) Some(low + math.abs(random % ((high - low) + 1))) else None
    }

    implicit val betweenByte:   Between[Byte]   = (low: Byte, high: Byte)     => { ps => chooseLong(low, high, ps.random.nextLong).map(_.toByte) }
    implicit val betweenChar:   Between[Char]   = (low: Char, high: Char)     => { ps => chooseLong(low, high, ps.random.nextLong).map(_.toChar) }
    implicit val betweenShort:  Between[Short]  = (low: Short, high: Short)   => { ps => chooseLong(low, high, ps.random.nextLong).map(_.toShort) }
    implicit val betweenInt:    Between[Int]    = (low: Int, high: Int)       => { ps => chooseLong(low, high, ps.random.nextLong).map(_.toInt) }
    implicit val betweenLong:   Between[Long]   = (low: Long, high: Long)     => { ps => chooseLong(low, high, ps.random.nextLong) }
    implicit val betweenFloat:  Between[Float]  = (low: Float, high: Float)   => { ps => chooseDouble(low, high, ps.random.nextDouble).map(_.toInt) }
    implicit val betweenDouble: Between[Double] = (low: Double, high: Double) => { ps => chooseDouble(low, high, ps.random.nextDouble).map(_.toInt) }

  }

}
